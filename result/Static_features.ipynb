{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.5\n",
      "tensorflow version: 2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/Documents/eBay/OOSLAClassifier/service/Classifier/Model/XGBRegressionModel.py:2: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  from pandas import np\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import sys\n",
    "from service.Classifier.DataLoader.DataLoader import DataLoader\n",
    "from service.Classifier.Enums.priority import Priority\n",
    "from service.Classifier.DataLoader.P2DataLoader import P2DataLoader\n",
    "from service.Classifier.DataLoader.P3DataLoader import P3DataLoader\n",
    "from service.Classifier.DataLoader.P4DataLoader import P4DataLoader\n",
    "from service.Classifier.Model.XGBRegressionModel import XGBRegressionModel\n",
    "from service.Classifier.PreProcessing.RegressionModelPreProcessor import RegressionModelPreProcessor\n",
    "import pickle\n",
    "import platform\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import csv\n",
    "from os import path\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "import csv\n",
    "import os.path\n",
    "from os import path\n",
    "import pathlib\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print('Python version:', platform.python_version())\n",
    "print('tensorflow version:', tf.__version__)\n",
    "sys.path.insert(0, os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeByPriority(priority):\n",
    "    # load new updated data via Features class\n",
    "    if priority == Priority.P2.value:\n",
    "        return P2DataLoader()\n",
    "    elif priority == Priority.P3.value:\n",
    "        return P3DataLoader()\n",
    "    elif priority == Priority.P4.value:\n",
    "        return P4DataLoader()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.Classifier.DataSplit.TrainTestSplit import TrainTestSplit\n",
    "from service.Classifier.Enums.dataTypeEnum import DataType\n",
    "\n",
    "def preprocessData(priority_value):\n",
    "\n",
    "    dataLoader = initializeByPriority(priority)\n",
    "    data_df = dataLoader.loadTrainingRawData()\n",
    "\n",
    "    # split data into train test 4:1\n",
    "    dataSplit = TrainTestSplit()\n",
    "    train_df, test_df = dataSplit.split(data_df)\n",
    "\n",
    "    # generate features\n",
    "    train_df, feature_names = dataLoader.transformRawDataToFeatures(train_df, DataType.TRAINDATA.value)\n",
    "    test_df, feature_names = dataLoader.transformRawDataToFeatures(test_df, DataType.VALIDATION.value)\n",
    "    print(train_df.shape)\n",
    "    print(test_df.shape)\n",
    "\n",
    "    # pre-processing the data based on model type\n",
    "    preprocessor = RegressionModelPreProcessor(feature_names)\n",
    "    train_X, train_y, test_X, test_y = preprocessor.preprocessing(train_df, test_df)\n",
    "    print(train_X.shape)\n",
    "    print(test_X.shape)\n",
    "    \n",
    "    return data_df, train_df, test_df, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "def getGCX():\n",
    "    url = \"http://paysplan.paysplan-ns.svc.33.tess.io/people/gcx/allNames\"\n",
    "    return requests.get(url).json()\n",
    "\n",
    "def checkGCX(row):\n",
    "    if row['Submitter'] in GCX['people']:\n",
    "        return 'Internal'\n",
    "    else:\n",
    "        return 'External'\n",
    "\n",
    "def extractLatestCategory(row):\n",
    "    try:\n",
    "        row['Category'][-1]['value']\n",
    "        return row['Category'][-1]['value']\n",
    "    except:\n",
    "        return 'NAN'\n",
    "\n",
    "def getStaticMetrics(data_df):\n",
    "    staticMetrics = data_df[[\"_id\", \"assignee\", \"reporter\",\"issueType\", \"summary\"]].copy()\n",
    "    \n",
    "    staticMetrics = staticMetrics.rename({'_id': \"issueKey\",'assignee': 'Owner', \"issueType\": 'Type', \n",
    "                                          'reporter': 'Submitter'}, axis='columns')\n",
    "    \n",
    "    staticMetrics['ESC'] = staticMetrics.apply(checkGCX, axis=1)\n",
    "    \n",
    "    with open('ExtarctedInfo.pickle', 'rb') as f:\n",
    "        allInfor = pickle.load(f)\n",
    "        \n",
    "    # Join the table \n",
    "    right = allInfor[[\"issueKey\",\"categoryBugs\", \"severity\" ]]\n",
    "    StaticMetricsResult = pd.merge(staticMetrics, right, how=\"left\", on=\"issueKey\")\n",
    "    \n",
    "    StaticMetricsResult = StaticMetricsResult.rename({'categoryBugs': 'Category', 'severity': 'Severity', 'summary': 'Summary'}, axis='columns')\n",
    "    return StaticMetricsResult\n",
    "\n",
    "def embeddingValues(col_name, staticMetrics):\n",
    "    List = staticMetrics[col_name].tolist()\n",
    "    uniqueListA = list(set(List))\n",
    "    \n",
    "    def getIndex(row):\n",
    "        return uniqueListA.index(row[col_name])\n",
    "\n",
    "    new_col_name = col_name + '_Emb'\n",
    "    staticMetrics[new_col_name] = staticMetrics.apply(getIndex, axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary = Pipeline([\n",
    "                ('selector', TextSelector(key='Summary')),\n",
    "                ('tfidf', TfidfVectorizer(stop_words='english'))\n",
    "            ])\n",
    "\n",
    "Owner_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Owner_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "Submitter_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Submitter_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "ESC_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='ESC_Emb')),\n",
    "                ('standard', StandardScaler())\n",
    "            ])\n",
    "Type_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Type_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "\n",
    "Severity_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Severity_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])\n",
    "Category_Emb =  Pipeline([\n",
    "                ('selector', NumberSelector(key='Category_Emb')),\n",
    "                ('standard', StandardScaler()),\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(submission, priority):\n",
    "    coefficients_Dict = {\"P1\": 1, \"P2\": 1, \"P3\": 1, \"ALL\": 1}\n",
    "    coefficients = coefficients_Dict[priority]\n",
    "    priorityDays_dict = {\"P1\": 20, \"P2\": 60, \"P3\": 90}\n",
    "    daysAllowedList = priorityDays_dict[priority]\n",
    "    \n",
    "    submission[\"prediction\"] = pd.Series(submission[\"ClosedDay\"] >= coefficients * daysAllowedList,\n",
    "                                         index=submission.index)\n",
    "    \n",
    "    submission[\"truth\"] = pd.Series(submission[\"Actual\"] >= daysAllowedList, index=submission.index)\n",
    "    # submission[\"issueType\"] = test_df[\"issueType\"]\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from service.Classifier.Enums.LabelEnum import LabelEnum\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, classification_report\n",
    "from service.Classifier.PreProcessing.Utils.dataValidator import DataValidator\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "feats = FeatureUnion([('Owner_Emb', Owner_Emb), \n",
    "                      ('Submitter_Emb', Submitter_Emb),\n",
    "                      ('ESC_Emb', ESC_Emb),\n",
    "                      ('Type_Emb', Type_Emb),\n",
    "                      ('Severity_Emb', Severity_Emb),\n",
    "                      ('Category_Emb', Category_Emb),\n",
    "                      ('Summary', Summary)])\n",
    "\n",
    "feature_processing = Pipeline([('feats', feats)])\n",
    "\n",
    "\n",
    "def evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy):\n",
    "\n",
    "    feature_processing.fit_transform(staticMetrics_trainX)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('regressor', XGBRegressor(max_depth=5, n_estimators=100, learning_rate=0.05)),\n",
    "    ])\n",
    "\n",
    "\n",
    "    pipeline.fit(staticMetrics_trainX, staticMetrics_trainy)\n",
    "\n",
    "    predictions = np.rint(pipeline.predict(staticMetrics_testX)).astype(np.int64)\n",
    "\n",
    "\n",
    "    submission = pd.DataFrame({'ClosedDay': predictions, 'Actual': staticMetrics_testy['ResolvedDay'].tolist()})\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(predictions, staticMetrics_testy))\n",
    "\n",
    "    mae = mean_absolute_error(predictions, staticMetrics_testy)\n",
    "\n",
    "    valid(submission, priority)\n",
    "\n",
    "    f1 = f1_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "    precision = precision_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "    recall = recall_score(submission[\"truth\"], submission[\"prediction\"])\n",
    "\n",
    "\n",
    "    print('rmse:', rmse)\n",
    "    print('mae:', mae)\n",
    "    print(confusion_matrix(submission[\"truth\"], submission[\"prediction\"]))\n",
    "    print(classification_report(submission[\"truth\"], submission[\"prediction\"]))\n",
    "    \n",
    "    return (staticMetrics_testy, predictions, submission[\"truth\"], submission[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_static_feature(priority):\n",
    "    \n",
    "    data_df, train_df,test_df, train_X, train_y, test_X, test_y = preprocessData(priority)\n",
    "\n",
    "    \n",
    "\n",
    "    staticMetrics = getStaticMetrics(data_df)\n",
    "    \n",
    "    staticMetrics['Category'] = staticMetrics.apply(extractLatestCategory, axis=1)\n",
    "\n",
    "    # \"\"\"\n",
    "    # Embedding all columns except \"Summary\"\n",
    "    # \"\"\"\n",
    "\n",
    "    colNames = [\"Owner\", \"Submitter\", \"Type\", \"ESC\", \"Category\", \"Severity\"]\n",
    "    \n",
    "    for colName in colNames:\n",
    "        embeddingValues(colName, staticMetrics)\n",
    "\n",
    "    staticMetrics = staticMetrics.rename({\"issueKey\": \"keyID\"}, axis='columns')\n",
    "    staticMetrics = staticMetrics.drop_duplicates(subset='keyID', keep=\"last\")\n",
    "    staticMetrics[\"keyID\"].is_unique\n",
    "\n",
    "    AllMetrics_train = pd.merge(train_df, staticMetrics, how=\"left\", on=\"keyID\")\n",
    "    AllMetrics_test = pd.merge(test_df, staticMetrics, how=\"left\", on=\"keyID\")\n",
    "\n",
    "\n",
    "    # get training data \n",
    "    staticMetrics_trainX = AllMetrics_train[[\"Owner_Emb\", \"Submitter_Emb\", \"ESC_Emb\", \"Type_Emb\", \"Severity_Emb\", \"Category_Emb\", \"Summary\"]]\n",
    "    staticMetrics_trainy = AllMetrics_train[[\"ResolvedDay\"]]\n",
    "    # get testing data \n",
    "    staticMetrics_testX = AllMetrics_test[[\"Owner_Emb\", \"Submitter_Emb\", \"ESC_Emb\", \"Type_Emb\", \"Severity_Emb\", \"Category_Emb\", \"Summary\"]]\n",
    "    staticMetrics_testy = AllMetrics_test[[\"ResolvedDay\"]]\n",
    "\n",
    "    return (staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)\n",
    "\n",
    "# static_X=np.concatenate((staticMetrics_trainX, staticMetrics_testX))\n",
    "# static_y = np.concatenate((staticMetrics_trainy, staticMetrics_testy))\n",
    "# print(static_X.shape)\n",
    "# print(static_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P1 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The project is not in embedding: PX\n",
      "The project is not in embedding: CSCNPLAT\n",
      "The project is not in embedding: GGRIP\n",
      "The project is not in embedding: PROBLEM\n",
      "The project is not in embedding: NATBEMCR\n",
      "(2648, 12)\n",
      "(646, 12)\n",
      "(2648, 8)\n",
      "(646, 8)\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P2.value\n",
    "GCX = getGCX()\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracted featrues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Owner_Emb</th>\n",
       "      <th>Submitter_Emb</th>\n",
       "      <th>ESC_Emb</th>\n",
       "      <th>Type_Emb</th>\n",
       "      <th>Severity_Emb</th>\n",
       "      <th>Category_Emb</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1667</td>\n",
       "      <td>696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Adyen Issue] DE - MP Unable to verify account...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>382</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Seller cannot cancel item from ResolutionCenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1938</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Top of funnel for B2C registration (PPA) has d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>188</td>\n",
       "      <td>1419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US UK - Email sent to members in German langua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1434</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MP Account still charged Add Rate Fee's  for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1049</td>\n",
       "      <td>1051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>MP: Member's payouts on hold due to USER_PAYOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1802</td>\n",
       "      <td>1350</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GCX unable to check Job Statuses - CSReadJobs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1667</td>\n",
       "      <td>1051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[Adyen Issue] MP: Possible Data Transmission I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1563</td>\n",
       "      <td>353</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MP - US - Member was charged for 2 labels but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1118</td>\n",
       "      <td>1336</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>CLONE - ALERT12866 - Global - Member unable to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Owner_Emb  Submitter_Emb  ESC_Emb  Type_Emb  Severity_Emb  Category_Emb  \\\n",
       "0       1667            696        1         0             1             1   \n",
       "1        382            142        0         0             2             4   \n",
       "2       1938           1213        0         0             2            10   \n",
       "3        188           1419        0         0             0             0   \n",
       "4       1434            353        1         0             0             0   \n",
       "5       1049           1051        1         0             2             4   \n",
       "6       1802           1350        0         0             0             0   \n",
       "7       1667           1051        1         0             2             3   \n",
       "8       1563            353        1         0             0             0   \n",
       "9       1118           1336        1         0             2            16   \n",
       "\n",
       "                                             Summary  \n",
       "0  [Adyen Issue] DE - MP Unable to verify account...  \n",
       "1    Seller cannot cancel item from ResolutionCenter  \n",
       "2  Top of funnel for B2C registration (PPA) has d...  \n",
       "3  US UK - Email sent to members in German langua...  \n",
       "4  MP Account still charged Add Rate Fee's  for C...  \n",
       "5  MP: Member's payouts on hold due to USER_PAYOU...  \n",
       "6  GCX unable to check Job Statuses - CSReadJobs ...  \n",
       "7  [Adyen Issue] MP: Possible Data Transmission I...  \n",
       "8  MP - US - Member was charged for 2 labels but ...  \n",
       "9  CLONE - ALERT12866 - Global - Member unable to...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staticMetrics_trainX.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "staticMetrics_trainX.to_csv(\"static.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1 reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse: 9.442112495204292\n",
      "mae: 7.671317829457364\n",
      "[[ 80 307]\n",
      " [ 28 230]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.21      0.32       387\n",
      "        True       0.43      0.89      0.58       258\n",
      "\n",
      "    accuracy                           0.48       645\n",
      "   macro avg       0.58      0.55      0.45       645\n",
      "weighted avg       0.62      0.48      0.43       645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p1_regression_true, p1_regression_pred, p1_classification_true, p1_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P2 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2740, 16)\n",
      "(668, 16)\n",
      "(2740, 12)\n",
      "(668, 12)\n",
      "rmse: 19.395775513869797\n",
      "mae: 14.154191616766466\n",
      "[[421  61]\n",
      " [135  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.76      0.87      0.81       482\n",
      "        True       0.46      0.27      0.34       186\n",
      "\n",
      "    accuracy                           0.71       668\n",
      "   macro avg       0.61      0.57      0.58       668\n",
      "weighted avg       0.67      0.71      0.68       668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P2.value\n",
    "\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n",
    "\n",
    "p2_regression_true, p2_regression_pred, p2_classification_true, p2_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get P3 Static Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fjirigesi/anaconda3/lib/python3.8/site-packages/pymongo/common.py:781: UserWarning: The value of ssl must be 'true' or 'false'\n",
      "  warnings.warn(str(exc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1563, 16)\n",
      "(382, 16)\n",
      "(1563, 12)\n",
      "(382, 12)\n",
      "rmse: 25.426827568720093\n",
      "mae: 17.12041884816754\n",
      "[[266   8]\n",
      " [ 95  13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.97      0.84       274\n",
      "        True       0.62      0.12      0.20       108\n",
      "\n",
      "    accuracy                           0.73       382\n",
      "   macro avg       0.68      0.55      0.52       382\n",
      "weighted avg       0.70      0.73      0.66       382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "priority = Priority.P3.value\n",
    "\n",
    "staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy = extract_static_feature(priority)\n",
    "\n",
    "p3_regression_true, p3_regression_pred, p3_classification_true, p3_classification_pred = evaluate_static_result(staticMetrics_trainX, staticMetrics_trainy, staticMetrics_testX, staticMetrics_testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
